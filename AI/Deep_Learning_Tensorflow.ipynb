{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Deep_Learning_Tensorflow.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyPBJjUGM2S4LeQQrCEnVQT2",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/xcellentbird/STUDY/blob/main/AI/Deep_Learning_Tensorflow.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Y5hkzLlzb8Zj"
      },
      "source": [
        "## TensorFlow: Neural"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LOIq73QycFDb"
      },
      "source": [
        "import tensorflow as tf\n",
        "import numpy as np"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qbMkoFdgbAzS"
      },
      "source": [
        "N, D, H = 64, 1000, 100"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kDqwcngucDbU"
      },
      "source": [
        "# input tensor\n",
        "x = tf.convert_to_tensor(np.random.randn(N, D), np.float32)\n",
        "\n",
        "# target tensor\n",
        "y = tf.convert_to_tensor(np.random.randn(N, D), np.float32)\n",
        "\n",
        "# weight\n",
        "w1 = tf.Variable(tf.random.uniform((D, H)))\n",
        "w2 = tf.Variable(tf.random.uniform((H, D)))"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2EstR0Mack_F"
      },
      "source": [
        "lr = 1e-6\n",
        "for epoch in range(20):\n",
        "  with tf.GradientTape() as tape: # dynamic computation\n",
        "    h = tf.maximum(tf.matmul(x, w1), 0) # layer, ReLU\n",
        "    y_pred = tf.matmul(h, w2) # layer2\n",
        "    diff = y_pred - y # error\n",
        "    loss = tf.reduce_mean(tf.reduce_sum(diff ** 2, axis=1)) # loss\n",
        "\n",
        "  # compute grad\n",
        "  gradients = tape.gradient(loss, [w1, w2])\n",
        "\n",
        "  w1.assign(w1 - lr * gradients[0])\n",
        "  w2.assign(w2 - lr * gradients[1])"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TPYSXq4yc6eV",
        "outputId": "ff2afef6-d159-436c-bc01-e44934182b52"
      },
      "source": [
        "gradients"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[<tf.Tensor: shape=(1000, 100), dtype=float32, numpy=\n",
              " array([[ 106.65317  , -229.56056  ,  244.22047  , ...,  387.68646  ,\n",
              "          125.75412  ,  355.15585  ],\n",
              "        [  18.040977 , -154.27551  ,  109.451965 , ..., -364.91553  ,\n",
              "            5.654018 ,  804.6157   ],\n",
              "        [  46.610996 ,  -93.416275 , -109.18049  , ..., -332.39496  ,\n",
              "         -122.52287  , -844.1428   ],\n",
              "        ...,\n",
              "        [ 271.49423  ,  220.42593  ,  983.1101   , ...,  -87.242836 ,\n",
              "          -91.432655 ,   34.775513 ],\n",
              "        [ 592.61346  , -110.44813  ,  234.08894  , ...,  393.41888  ,\n",
              "         -201.97852  ,  279.60574  ],\n",
              "        [  -3.6907933,   59.504856 , -468.314    , ...,  996.1352   ,\n",
              "          163.98288  ,  294.79688  ]], dtype=float32)>,\n",
              " <tf.Tensor: shape=(100, 1000), dtype=float32, numpy=\n",
              " array([[ 4.676632 ,  1.8077067,  4.0906067, ...,  4.3303995,  3.7657716,\n",
              "          3.8067212],\n",
              "        [ 1.2126491,  1.1211177,  1.8127842, ...,  1.4323751,  1.2389755,\n",
              "          1.6853117],\n",
              "        [ 8.310822 ,  8.584664 ,  6.050478 , ...,  8.02374  ,  4.278997 ,\n",
              "          7.0321126],\n",
              "        ...,\n",
              "        [21.026209 , 20.37541  , 25.237179 , ..., 22.704998 , 12.782484 ,\n",
              "         17.210691 ],\n",
              "        [ 2.8189054,  2.3652983,  3.0449688, ...,  2.2672126,  3.2131584,\n",
              "          3.5757866],\n",
              "        [12.476326 , 16.665339 , 15.647833 , ..., 16.462465 , 13.088723 ,\n",
              "         13.016223 ]], dtype=float32)>]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vZ2aMTSWsWYl"
      },
      "source": [
        "## TensorFlow: Optimizer"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QvKbWu7MsdNN"
      },
      "source": [
        "lr = 1e-6\n",
        "optimizer = tf.optimizers.SGD(lr)"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Y4UyaH26sWID"
      },
      "source": [
        "for epoch in range(20):\n",
        "  with tf.GradientTape() as tape: # dynamic computation\n",
        "    h = tf.maximum(tf.matmul(x, w1), 0) # layer, ReLU\n",
        "    y_pred = tf.matmul(h, w2) # layer2\n",
        "    diff = y_pred - y # error\n",
        "    loss = tf.reduce_mean(tf.reduce_sum(diff ** 2, axis=1)) # loss\n",
        "\n",
        "  # compute grad\n",
        "  gradients = tape.gradient(loss, [w1, w2])\n",
        "\n",
        "  # update weights\n",
        "  optimizer.apply_gradients(zip(gradients, [w1, w2]))"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OSd4F5FWs5kM"
      },
      "source": [
        "## TensorFlow: Loss"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LUReUW1ZtNbh"
      },
      "source": [
        "loss_fn = tf.losses.MeanSquaredError()"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ByL6SP_KdBcK"
      },
      "source": [
        "for epoch in range(20):\n",
        "  with tf.GradientTape() as tape: # dynamic computation\n",
        "    h = tf.maximum(tf.matmul(x, w1), 0) # layer, ReLU\n",
        "    y_pred = tf.matmul(h, w2) # layer2\n",
        "    diff = y_pred - y # error\n",
        "    \n",
        "    # loss\n",
        "    loss = loss_fn(y_pred, y)\n",
        "\n",
        "  # compute grad\n",
        "  gradients = tape.gradient(loss, [w1, w2])\n",
        "\n",
        "  # update weights\n",
        "  optimizer.apply_gradients(zip(gradients, [w1, w2]))"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uoLlFkyxtaT-"
      },
      "source": [
        "## Keras: High-Level Wrapper"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rXpLWGixtkU0"
      },
      "source": [
        "N, D, H = 64, 1000, 100"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YqLNf0fRtQCU"
      },
      "source": [
        "# input tensor\n",
        "x = tf.convert_to_tensor(np.random.randn(N, D), np.float32)\n",
        "\n",
        "# target tensor\n",
        "y = tf.convert_to_tensor(np.random.randn(N, D), np.float32)"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PiH8cj_YvGUH"
      },
      "source": [
        "### method 1"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "G2P8c3CPtm7N"
      },
      "source": [
        "# model(weights)\n",
        "model = tf.keras.Sequential()\n",
        "model.add(tf.keras.layers.Dense(H, input_shape=(D,), activation=tf.nn.relu))\n",
        "model.add(tf.keras.layers.Dense(D))"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8YniiuHrt3GE"
      },
      "source": [
        "lr = 1e-6\n",
        "optimizer = tf.optimizers.SGD(lr)\n",
        "loss_fn = tf.losses.MeanSquaredError()"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oSt1RKPduIa2"
      },
      "source": [
        "for epoch in range(20):\n",
        "  with tf.GradientTape() as tape:\n",
        "    y_pred = model(x)\n",
        "    loss = loss_fn(y_pred, y)\n",
        "  \n",
        "  # apply gradient to all trainable variables(weights) in model\n",
        "  gradients = tape.gradient(loss, model.trainable_variables)\n",
        "  optimizer.apply_gradients(zip(gradients, model.trainable_variables))"
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WnQ0iqeVu96i"
      },
      "source": [
        "### method 2"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EzqTh7kJu_Po"
      },
      "source": [
        "# model(weights)\n",
        "model = tf.keras.Sequential()\n",
        "model.add(tf.keras.layers.Dense(H, input_shape=(D,), activation=tf.nn.relu))\n",
        "model.add(tf.keras.layers.Dense(D))"
      ],
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "F8AvCssmvc90"
      },
      "source": [
        "lr = 1e-6\n",
        "optimizer = tf.optimizers.SGD(lr)\n",
        "loss_fn = tf.losses.MeanSquaredError()"
      ],
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4Wz4lLUtvd8X"
      },
      "source": [
        "model.compile(loss=loss_fn, optimizer=optimizer)"
      ],
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "L-HbZAPZvkzt",
        "outputId": "7432102e-2022-403a-90a8-649ff6d69d0f"
      },
      "source": [
        "history = model.fit(x, y, epochs=50, batch_size=N)"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/50\n",
            "1/1 [==============================] - 0s 235ms/step - loss: 1.1545\n",
            "Epoch 2/50\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 1.1545\n",
            "Epoch 3/50\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 1.1545\n",
            "Epoch 4/50\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 1.1545\n",
            "Epoch 5/50\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 1.1545\n",
            "Epoch 6/50\n",
            "1/1 [==============================] - 0s 3ms/step - loss: 1.1545\n",
            "Epoch 7/50\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 1.1545\n",
            "Epoch 8/50\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 1.1545\n",
            "Epoch 9/50\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 1.1545\n",
            "Epoch 10/50\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 1.1545\n",
            "Epoch 11/50\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 1.1545\n",
            "Epoch 12/50\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 1.1545\n",
            "Epoch 13/50\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 1.1545\n",
            "Epoch 14/50\n",
            "1/1 [==============================] - 0s 3ms/step - loss: 1.1545\n",
            "Epoch 15/50\n",
            "1/1 [==============================] - 0s 3ms/step - loss: 1.1545\n",
            "Epoch 16/50\n",
            "1/1 [==============================] - 0s 14ms/step - loss: 1.1545\n",
            "Epoch 17/50\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 1.1545\n",
            "Epoch 18/50\n",
            "1/1 [==============================] - 0s 3ms/step - loss: 1.1545\n",
            "Epoch 19/50\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 1.1545\n",
            "Epoch 20/50\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 1.1545\n",
            "Epoch 21/50\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 1.1545\n",
            "Epoch 22/50\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 1.1545\n",
            "Epoch 23/50\n",
            "1/1 [==============================] - 0s 3ms/step - loss: 1.1545\n",
            "Epoch 24/50\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 1.1545\n",
            "Epoch 25/50\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 1.1545\n",
            "Epoch 26/50\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 1.1545\n",
            "Epoch 27/50\n",
            "1/1 [==============================] - 0s 3ms/step - loss: 1.1545\n",
            "Epoch 28/50\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 1.1545\n",
            "Epoch 29/50\n",
            "1/1 [==============================] - 0s 3ms/step - loss: 1.1545\n",
            "Epoch 30/50\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 1.1545\n",
            "Epoch 31/50\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 1.1545\n",
            "Epoch 32/50\n",
            "1/1 [==============================] - 0s 3ms/step - loss: 1.1545\n",
            "Epoch 33/50\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 1.1545\n",
            "Epoch 34/50\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 1.1545\n",
            "Epoch 35/50\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 1.1545\n",
            "Epoch 36/50\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 1.1545\n",
            "Epoch 37/50\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 1.1545\n",
            "Epoch 38/50\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 1.1545\n",
            "Epoch 39/50\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 1.1545\n",
            "Epoch 40/50\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 1.1545\n",
            "Epoch 41/50\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 1.1545\n",
            "Epoch 42/50\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 1.1545\n",
            "Epoch 43/50\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 1.1545\n",
            "Epoch 44/50\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 1.1545\n",
            "Epoch 45/50\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 1.1545\n",
            "Epoch 46/50\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 1.1545\n",
            "Epoch 47/50\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 1.1545\n",
            "Epoch 48/50\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 1.1545\n",
            "Epoch 49/50\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 1.1545\n",
            "Epoch 50/50\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 1.1545\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wANAN_sZvu6t"
      },
      "source": [
        "# @tf.function 을 사용하여 static_graph를 이용할 수도 있다.\n",
        "# 모델의 구조에 따라 성능이 더 좋을 수도 더 나쁠 수도 있다.\n",
        "\n",
        "@tf.function\n",
        "def model_static(x, y):\n",
        "  y_pred = model(x)\n",
        "  loss = loss_fn(y_pred, y)\n",
        "  return y_pred, loss\n",
        "\n",
        "def model_dynamic(x, y):\n",
        "  y_pred = model(x)\n",
        "  loss = loss_fn(y_pred, y)\n",
        "  return y_pred, loss"
      ],
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VFFiHKNZxyDf"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}