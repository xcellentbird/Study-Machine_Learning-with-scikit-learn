# Kaggle

- 2021. 5. 1: Titanic 튜토리얼 복습. 원리와 이론은 이해가 간다. 사실 Tensorflow, Keras, Scikit_learn같은 머신 러닝 툴보다 Pandas, Matploblib, Seaborn과 같은 데이터 처리 및 시각화 툴을 쓰는 것이 더 어렵게 느껴진다. '요소의 각 칼럼 데이터를 모두 취합해 통계를 내고 싶은데, 어떻게 해야하지?' 와 같은 목표가 있지만, 쉽게 만들지를 못한다... 더해서 머신러닝 모델은 지금 그냥 쓰는 느낌이다. '아 이렇게 하면 더 잘 된다고 했으니, 이 파라미터를 설정해보자~' 정도다. 원리는 이해하고 있지만, 장점과 단점, 그리고 어떨 때에 쓰면 좋을 지 알지 못한다... 써본 모델의 파라미터와 특징을 정리할 공간이 필요하다. 이 파라미터는 어떠한 역할을 하고, 어떤 영향을 주는지, 어느 곳에서 쓰일 수 있는 건지 알아야한다. 가끔 전문가들은 써보고 감을 익혀야한다고 한다... 그냥 많이 찾고, 물어보고, 사용하는 수 밖에 없을 것 같다. 캐글 문제를 많이 풀어보고는 싶지만, 데이터 정리하는 데에 시간 소요가 너무 많아서 풀면서 많이 지치는 편이다. 그래도 원하고자 하는 시각화가 될 때, 기분은 좋다. 많이 풀자  
- 2021. 5. 2: 어느 기업의 입사 테스트, Criteo - Conversion 예측 문제. 암호화(?)된 데이터값('A351256VS42D21'와 같은)을 어떻게 봐야하나...? 아스키 코드 조차 아니였다. 알아낸 건 Product_Price  feature 값에 의해 크게 Conversion이 좌지우지 된다는 것이다. 'Feature 하나만 쓸 거면 모델링을 할 필요가 있을까?' 생각했다. 데이터를 처리하고 생각하는 데에만 이틀이 걸렸다... Flask 프레임워크를 이용해서 서비스도 많들어야 하는데, 쉽지가 않다. Django든, Flask든 Python을 이용한 간단한 서버 만드는 법을 익힐 필요가 있다. 그리고 테스트 과제는 결국 제출하지 못했다. 하루 이상은 더 걸렸을 것 같다. ~~한 문제에 3~4일??ㅜㅠ~~  
- 2021. 5. 3: 로또 데이터를 이용한 당첨, 낙첨 예측. 사실 무의미한 예측이라고 생각한다. 각 Column(데이터)들은 target(당첨, 낙첨) 값과 서로 독립적이라고 보기 때문이다. 일단, 그래도 해보자는 생각으로, 각 칸의 숫자와 보너스 숫자를 모두 추합하여 1-45 중 어떤 번호가 많이 나오는지, value_counts()를 통해 데이터를 정리했다. 그리고 가장 많이 나오는 숫자들(전체의 1/3)과 적게 나오는 숫자들(1/3), 그리고 나머지 1/3을 모아 각각 2,0,1 값들로 재설정하였다. 그리고 각 열에 0이 몇개인지, 1이 몇개, 2가 몇개인지 알 수 있는 feature 3개를 만들었다. 그리고 KMeans 모델을 이용해, 해당 feature값들로만 당첨, 낙첨 여부를 판단하도록 만들었다. 사실 1이 몇개인지를 알려주는 feature는 무의미하다는 사실을 알아냈고, 예측 정확도 아주 약간 좋다는 것을 알게 되었다.(55~60%정도?) 그리고 역시 숫자 데이터는 무의미한 데이터라고 생각된다.~~차라리 이중슬릿 실험의 관찰자 효과 데이터를 주는 게 더 좋을지도~~  
